\documentclass[a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{RJournal}
\usepackage{amsmath,amssymb,array}
\usepackage{booktabs}

%% load any required packages here

\begin{document}

%% do not edit, for illustration only
\sectionhead{Contributed research article}
\volume{XX}
\volnumber{YY}
\year{20ZZ}
\month{AAAA}

\begin{article}

  \title{An efficient and readable syntax for defining named capture
  regular expressions in R code}

\author{by Toby Dylan Hocking}

\maketitle

\abstract{Regular expressions are powerful tools for manipulating
  non-tabular textual data. For many tasks (visualization, machine
  learning, etc), tables of numbers must be extracted from such data
  before processing by other R functions. We present the R package
  namedCapture, which facilitates such tasks by providing a new
  user-friendly syntax for defining regular expressions in R code. We
  begin by describing the history of regular expressions and their
  usage in R. We then describe the new features of the namedCapture
  package, and provide detailed comparisons with related R packages
  (rex, stringr, stringi, tidyr, rematch2, re2r).}
\section{Introduction}

Today regular expression libraries are powerful and widespread tools
for text processing. A regular expression \textbf{pattern} is
typically a character string that defines a set of possible
\textbf{matches} in some other \textbf{subject} strings. For example
the pattern \verb|o+| matches one or more lower-case o characters; it
would match the last two characters in the subject \verb|foo|, and it
would not match in the subject \verb|bar|. 

The focus of this article is regular expressions with capture groups,
which are used to extract subject substrings. Capture groups are
typically defined using parentheses. For example, the pattern
\verb|[0-9]+| matches one or more digits (e.g. \verb|314| but not
\verb|3.14|), and the pattern \verb|[0-9]+-[0-9]+| matches a range of
digits (e.g. \verb|9-5|). The pattern \verb|([0-9]+)-([0-9]+)| will
perform matching identically, but provides access by number/index to
the strings matched by the capturing sub-patterns enclosed in
parentheses (group 1 matches \verb|9|, group 2 matches \verb|5|). The
pattern \verb|(?<start>[0-9]+)-(?<end>[0-9]+)| further provides access
by name to the captured sub-strings (\verb|start| group matches
\verb|9|, \verb|end| group matches \verb|5|). In R named capture
groups are useful in order to create more readable regular expressions
(names document the purpose of each sub-pattern), and to create more
readable R code (named references to captured groups are better than
numbered references).

We begin by providing a brief history of regular
expressions and their usage in \R. We then provide an overview of
current R packages for regular expressions.

\subsection{Origin of regular expressions and named capture groups}

Regular expressions were first proposed on paper
by \citet{Kleene56}. Among the first uses of a regular expression in
computers was for searching in a text editor \citep{Thompson68} and
lexical processing of source code \citep{Johnson68}. 

A capture group in a regular expression is used to extract text that
matches a sub-pattern. In 1974, Thompson wrote the \texttt{grep}
command line program, which was among the first to support capture
groups \citep{Friedl2002}. In that program, backslash-escaped
parentheses \verb|\(\)| were used to open and close each capture
group, which could then be referenced by number (\verb|\1| for the
first capture group, etc).

The idea for named capture groups seems to have originated in 1994
with the contributions of Tracy Tims to Python 1.0.0, which used the
\verb|\(<labelname>...\)| syntax
\citep{Python-1.5.2-Misc-HISTORY}. Python 1.5 introduced the
\verb|(?P<labelname>...)| syntax for name capture groups
\citep{python-1.5-Doc-libre.tex}; the P was used to indicate that the
syntax was a Python extension to the standard.

Perl-Compatible Regular Expressions (PCRE) is a C library that is now
a widely used in free/open-source software tools such as Python and R.
PCRE introduced support for named capture in 2003, based on the Python
syntax \citep{pcre1-changelog.txt}. Starting in 2006, it supported the
\verb|(?<labelname>...)| and \verb|(?'labelname'...)| syntax, to be
consistent with Perl and .NET \citep{pcre1-changelog.txt}.

The first regular expression support in R was provided by the TRE C
library \citep{TRE}. Although TRE supports capture groups, it does not
allow capture groups to be named. PCRE was first included in R version
1.6.0 in 2002 \citep{R.NEWS.1.txt}. The base R functions
\verb|regexpr| and \verb|gregexpr| can be given the \verb|perl=TRUE|
argument in order to use the PCRE library, or \verb|perl=FALSE| to use
the TRE C library. A major difference between the two libraries is
that TRE provides fast polynomial time match algorithms, whereas PCRE
is exponential time in the worst case. Although for most patterns the
time difference is negligible, malicious patterns can make PCRE run
quite a bit slower (Section~\ref{sec:timings}).

The original versions of \verb|regexpr| and \verb|gregexpr| only
returned the position/length of the text matched by an entire regex,
not the capture groups (even though this is suppored in TRE/PCRE). I
wrote the C code that uses PCRE to extract the text matched by each
named capture group \citep{HockingBug2011}, which was accepted into R
starting with version 2.14. I presented a lightning talk at useR 2011
that showcased the new functionality \citep{HockingUseR2011}.

\subsection{Related R packages for capturing regular expressions}

Since the introduction of named capture support in base R version
2.14, several packages have been developed which use this
functionality, and other packages have been developed which use other
C libraries (Table~\ref{tab:Clib}). Each package supports different
options for subject/pattern input, extracted text outputs, named
capture groups, and type conversion (Table~\ref{tab:features}).

The utils package now includes the strcapture function, which uses the
base regexec function (also introduced in R-2.14) to extract the first
match as a data.frame with one row per subject, and one column per
capture group. It allows capture group names/types to be specified in
a prototype data.frame argument, but does not allow capture group
names in the regex pattern itself. PCRE is used with \verb|perl=TRUE|
and TRE is used with \verb|perl=FALSE|.
 
The rematch2 package provides the \verb|re_match| function which
extracts the first match using the base \verb|regexpr| function
\citep{rematch2}. It also provides the \verb|re_match_all| function
which extracts all matches using the base \verb|gregexpr| function. In
both cases the output is a tibble (a data.frame subclass) with one row
for each subject (for all matches a list column is used). PCRE is used
with \verb|perl=TRUE| and TRE is used with \verb|perl=FALSE|. Although
TRE supports capture groups (and can be used via the base R regexec
function), capture groups are not supported in rematch2 with
\verb|perl=FALSE| (because it uses the base regexpr/gregexpr functions
which do not return group info for TRE). Named capture groups are
supported in rematch2 with \verb|perl=TRUE|.

The stringi package provides the \verb|stri_match| and
\verb|stri_match_all| functions, which use the ICU C library
\citep{stringi}. The stringr package provides the \verb|str_match| and
\verb|str_match_all| functions, which simply call the analogous
functions from stringi. Capture groups are supported but named groups
are not, so groups must be extracted by number. The \verb|stri_match|
function returns a character matrix with one row for each subject and
one column for each capture group. The \verb|stri_match_all| function
returns a list with one element for each subject; each element is a
data frame with one row for each match, and one column for each
capture group.

The re2r package provides the \verb|re2_match| and
\verb|re2_match_all| functions, which use the RE2 C++ library
\citep{re2r}. The outputs of these functions are consistent with the
stringi/stringr package. The input regex pattern may be specified as
a character string or as a pre-compiled regex object (which
results in faster matching if the regex is used with several calls to
matching functions). Like TRE, the RE2 library guarantees polynomial
time complexity, which is useful to avoid denial-of-service attacks
from malicious patterns (see Section~\ref{sec:timings}).

The rex package provides the \verb|re_matches| function which supports
named capture groups, and always uses PCRE \citep{rex}. By default it
returns the first match (using the base \verb|regexpr| function), as a
data.frame with one row for each subject, and one column for each
capture group. If the \verb|global=TRUE| argument is given,
\verb|gregexpr| is used to return all matches as a list of
data.frames. A unique feature of the rex package is a set of functions
for defining a regular expression in R code, which is then converted
to a standard PCRE regex pattern string (for a detailed comparison
with the proposed syntax of the namedCapture package, see
Section~\ref{sec:rex}).

The tidyr package provides the \verb|extract| function which uses the
ICU library, so does not support regex patterns with named capture
groups \citep{tidyr}. The subject is specified via the first two
arguments: (1) a data.frame, and (2) a column name. The pattern is
specified via the second two arguments: (3) a character vector for the
capture group names, and (4) the regex pattern string (it is an error
if the number of capture group names does not match the number of
capture groups in the regex pattern). The pattern is used to find the
first match in each subject. The return value is a data.frame with the
same number of rows as the input, but without the subject column, and
with an additional column for each capture group.

\begin{table}
  \centering
\begin{tabular}{llll}
Package      & First match              & All matches             & C library  \\
\hline
 base         & regexpr                  & gregexpr                & PCRE/TRE \\
 utils        & strcapture               & NA                      & PCRE/TRE \\
 rematch2     & re\_match                 & re\_match\_all            & PCRE/TRE\\
 namedCapture & str\_match\_*, df\_match\_variable          & str\_match\_all\_*     & PCRE\\
 rex          & re\_matches(global=FALSE) & re\_matches(global=TRUE) & PCRE\\
 stringr      & str\_match                & str\_match\_all           & ICU\\
 stringi      & stri\_match               & stri\_match\_all          & ICU\\
 tidyr        & extract                  & NA                      & ICU\\
 re2r         & re2\_match                & re2\_match\_all           & RE2
\end{tabular}
  \caption{R packages that provide functions for extracting first/all regex matches, and C library used.}
  \label{tab:Clib}
\end{table}


\begin{table}
  \centering
\begin{tabular}{llllll}
Package & subject & pattern      & outputs     & named & types \\
\hline
base & chr     & chr          & mat/list    & yes   & no    \\
utils::strcapture & chr     & chr          & df          & no    & some  \\
rematch2 & chr     & chr          & tibble      & yes   & no    \\
namedCapture & chr/df/dt   & verbose      & mat/list/df/dt       & yes   & any   \\
rex & chr     & verbose      & df/list          & yes   & no    \\
stringr & chr     & chr          & mat/list    & no    & no    \\
stringi & chr     & chr          & mat/list    & no    & no    \\
tidyr::extract & df/dt   & chr          & df/dt       & no    & some  \\
re2r & chr     & chr/compiled & df/list     & yes   & no    
\end{tabular}
  \caption{R packages provide different options for subject/pattern input, extracted text outputs, named capture groups, and type conversion.}
  \label{tab:features}
\end{table}

\section{The namedCapture package}

The namedCapture package provides functions for extracting numeric
data tables from non-tabular text data using named capture regular
expressions. It uses the PCRE library via the base \verb|regexpr| and
\verb|gregexpr| functions.
The main design features of the namedCapture package are
inspired by the base R system, which provides such good support for
naming objects, and referring to objects by name. In particular, the namedCapture package supports 
\begin{itemize}
\item Specifying capture groups with names in a regular expression
  string, and stopping with an informative error if there are un-named
  capture groups.
\item Output with rownames or list names taken from the 'name' capture group.
\item A syntax for specifying capture group names via named arguments
  in R code.
\item Specifying a function for each named capture group,
  which converts captured text from character to other arbitrary types.
\item Saving sub-patterns to R variables, and re-using them multiple
  times in one or several patterns in order to avoid repetition.
\end{itemize}

The main functions provided by the namedCapture package are summarized
in Table~\ref{tab:functions}. We begin by introducing the \verb|*_named| functions, which take three arguments.

\begin{table}
  \centering \begin{tabular}{llll}
  First match & All matches &  Arguments \\
  \hline
  \verb|str_match_named| & \verb|str_match_all_named| & chr subject, chr pattern, functions \\
  \verb|str_match_variable|  & \verb|str_match_all_variable| & chr subject, chr/list/function,  ... \\
  \verb|df_match_variable| & NA & df subject,  chr/list/function, ...
  \end{tabular}
  \caption{Functions of the
  namedCapture package. The first argument of each funtion specifies
  the subject, as either a character vector (for \texttt{str\_*})
  functions, or a data.frame
  (for \texttt{df\_match\_variable}). The \texttt{*\_named} functions
  require three arguments, whereas the \texttt{*\_variable} functions
  take a variable number of arguments.}  \label{tab:functions}
\end{table}

\subsection{Three argument syntax}

The most basic functions of the namedCapture package
are \verb|str_match_named| and \verb|str_match_all_named|, which accept exactly three arguments:
\begin{itemize}
\item subject: a character vector from which we want to extract
  tabular data.
\item pattern: the (character scalar) regular expression with named
  capture groups used for extraction.
\item fun.list: a list with names that correspond to capture groups,
  and values are functions used to convert the extracted character
  data to other (typically numeric) types.
\end{itemize}

For an example, we consider subjects containing genomic positions:

<<subject>>=

chr.pos.subject <- c(
  "chr10:213,054,000-213,055,000",
  "chrM:111,000",
  "this will not match",
  NA, # neither will this.
  "chr1:110-111 chr2:220-222") # two possible matches.

@

These subjects consist of a chromosome name string, a colon, a start
position, and optionally a dash and and end position. The following
pattern is used to extract those data:

<<chrPosPattern>>=

chr.pos.pattern <- paste0(
  "(?<chrom>.*?)",
  ":",
  "(?<chromStart>[0-9,]+)",
  "(?:",
    "-",
    "(?<chromEnd>[0-9,]+)",
  ")?")

@

The pattern above is defined using paste0, writing each named capture
group on a separate line, which increases readability of the pattern.
By default
the \verb|str_match_named| function returns a character matrix with
one row for each subject and one column for each capture group. Column
names are taken from the group names that were specified in the
regular expression pattern:

<<chrPosNoTypes>>=

(match.mat <- namedCapture::str_match_named(
  chr.pos.subject, chr.pos.pattern))
str(match.mat)

@


Note that the third argument (list of conversion functions) is omitted
in the code above. In that case, the return value is a character
matrix, in which missing values indicate missing subjects or no
match. The empty string is used for optional groups which are not used
in the match (e.g. chromEnd group/column for second subject).

However we often want to extract numeric data; in this case we want to
convert chromStart/End to integers. You can do that by supplying a
named list of conversion functions as the third argument. Each
function should take exactly one argument, a character vector (data in
the matched column/group), and return a vector of the same size. The
code below specifies the `int.from.digits` function for both `chromStart`
and `chromEnd`:

<<chrPosNoTypes>>=

int.from.digits <- function(captured.text){
  as.integer(gsub("[^0-9]", "", captured.text))
}
conversion.list <- list(
  chromStart=int.from.digits,
  chromEnd=int.from.digits)
(match.df <- namedCapture::str_match_named(
  chr.pos.subject, chr.pos.pattern, conversion.list))
str(match.df)

@

Note that a data.frame is returned when the third argument is
specified, in order to handle non-character data types returned by the
conversion functions.

In the examples above the last subject has two possible
matches, but only the first is returned by \verb|str_match_named|. Use
\verb|str_match_all_named| to get all matches in each subject (not just the
first match).

<<allChrPos>>=

namedCapture::str_match_all_named(
  chr.pos.subject, chr.pos.pattern, conversion.list)

@

As shown above, the result is a list with one element for
each subject. Each list element is a data.frame with one row for each
match.

\subsection{Named output}

If the subject is named, its names will be used to name the output
(rownames or list names).

<<namedSubject>>=

named.subject.vec <- c(
  ten="chr10:213,054,000-213,055,000",
  M="chrM:111,000",
  two="chr1:110-111 chr2:220-222") # two possible matches.
namedCapture::str_match_named(
  named.subject.vec, chr.pos.pattern, conversion.list)
namedCapture::str_match_all_named(
  named.subject.vec, chr.pos.pattern, conversion.list)

@

This feature makes it easy to select particular subjects/matches by
name. 

If the pattern specifies the \verb|name| group, then it will be used
for the rownames of the output, and it will not be included as a
column. However if the subject has names, and the `name` group is
specified, then the subject names are used to name the output (and the
`name` column is included in the output).

<<namedSubjectPattern>>=

name.pattern <- paste0(
  "(?<name>.*?)",
  ":",
  "(?<chromStart>[0-9,]+)",
  "(?:",
    "-",
    "(?<chromEnd>[0-9,]+)",
  ")?")
namedCapture::str_match_named(
  unname(named.subject.vec), name.pattern, conversion.list)
namedCapture::str_match_named(
  named.subject.vec, name.pattern, conversion.list)
namedCapture::str_match_all_named(
  named.subject.vec, name.pattern, conversion.list)

@

\subsection{Variable argument syntax}

In this section we introduce the variable argument syntax used in the
\verb|*_variable| functions, which is motivated by the desire to avoid
repetitive/boilerplate code. In the previous sections we defined the pattern using the
paste0 boilerplate, which is used to break the pattern over several
lines for clarity. We begin by introducing
\verb|str_match_variable|, which extracts the first match from each
subject. Using the variable argument syntax, we can omit
paste0, and simply supply the pattern strings to
\verb|str_match_variable| directly,

<<strMatchNamed>>=

namedCapture::str_match_variable(
  chr.pos.subject, 
  "(?<chrom>chr.*?)",
  ":",
  "(?<chromStart>[0-9,]+)",
  "(?:",
    "-",
    "(?<chromEnd>[0-9,]+)",
  ")?")

@

We can further simplify by removing the named capture groups from the
strings, and adding names to the corresponding arguments. For
\verb|name1="pattern1"|, namedCapture internally generates/uses the regex
\verb|(?<name1>pattern1)|.

<<namedArgs>>=

namedCapture::str_match_variable(
  chr.pos.subject, 
  chrom="chr.*?",
  ":",
  chromStart="[0-9,]+",
  "(?:",
    "-",
    chromEnd="[0-9,]+",
  ")?")

@

We can add type conversion functions on the same line as the
definition of the named group:

<<inlineconversion>>=

namedCapture::str_match_variable(
  chr.pos.subject, 
  chrom="chr.*?",
  ":",
  chromStart="[0-9,]+", int.from.digits,
  "(?:",
    "-",
    chromEnd="[0-9,]+", int.from.digits,
  ")?")

@

Note the repetition in the chromStart/End lines -- the same pattern
and type conversion function is used for each group. This repetition
can be avoided by creating and using a sub-pattern list variable,

<<subPatternList>>=

int.pattern <- list("[0-9,]+", int.from.digits)
namedCapture::str_match_variable(
  chr.pos.subject, 
  chrom="chr.*?",
  ":",
  chromStart=int.pattern,
  "(?:",
    "-",
    chromEnd=int.pattern,
  ")?")

@

Finally, the non-capturing group can be replaced by an un-named list:

<<nonCapturingList>>=

namedCapture::str_match_variable(
  chr.pos.subject, 
  chrom="chr.*?",
  ":",
  chromStart=int.pattern,
  list(
    "-",
    chromEnd=int.pattern
  ), "?")

@

In summary, the \verb|str_match_variable| function takes a variable number of arguments, and allow for a shorter, less repetitive, and thus more user-friendly syntax:
\begin{itemize}
\item The first argument is the subject character vector.
\item The other arguments specify the pattern, via character strings,
  functions, and/or lists.
\item If a pattern (character/list) is named, we use the argument name in R for the capture
  group name in the regex.
\item Each function is used to convert the text extracted by the previous
  named pattern argument. (type conversion can only be used with named R arguments, NOT with explicitly specified named groups in regex strings)
\item R sub-pattern variables
  may be used to avoid repetition in the definition of the pattern and type conversion functions.
\item Each list generates a group in the regex (named list = named capture group, un-named list = non-capturing group).
\item All patterns are pasted together in the order that they appear in
  the argument list.
\end{itemize}

\subsection{Extract all patterns from a file}

The variable argument syntax can also be used with
\verb|str_match_all_variable|, which is for the common case of extracting
each match from a multi-line text file. In this section we demonstrate
how to use \verb|str_match_all_variable| to extract data.frames from a
loosely structured text file.

<<trackDb>>=

trackDb.txt.gz <- system.file(
  "extdata", "trackDb.txt.gz", package="namedCapture")
trackDb.vec <- readLines(trackDb.txt.gz)

@

Some representative lines from that file are shown below.

<<catTrackDB>>=

cat(trackDb.vec[78:107], sep="\n")

@

Each block of text begins with "track" and includes several lines of
data before the block ends with two consecutive newlines. That pattern
is coded below using a regex:

<<fieldsDF>>=

fields.df <- namedCapture::str_match_all_variable(
  trackDb.vec,
  "track ",
  name="\\S+",
  fields="(?:\n[^\n]+)*",
  "\n")
head(fields.df)

@

Note that this function assumes that its first argument is a character
vector with one element for each line in a file. Therefore the result
contains no information about which subject element each match comes
from (to get that, use \verb|str_match_all_named|). The code above creates
a data frame with one row for each track block, with rownames given by
the track line (because of the capture group named name), and one
fields column which is a string with the rest of the data in that
block.

Each block has a variable number of lines/fields. Each line starts
with a field name, followed by a space, followed by the field
value. That regex is coded below:

<<fieldsList>>=

fields.list <- namedCapture::str_match_all_named(
  fields.df[, "fields"], paste0(
    "\\s+",
    "(?<name>.*?)",
    " ",
    "(?<value>[^\n]+)"))
fields.list[12:14]

@

The result is a list of data frames. 
There is a list element for each block, named by track. Each list
element is a data frame with one row per field defined in that
block (rownames are field names). The names/rownames make it easy
to write R code that selects individual elements by name.

In the example above we extracted all fields from all tracks (using
two regexes, one for the track, one for the field). In the example
below we extract only the bigDataUrl field for each track, and split
sample names into separate columns (using a single regex for the
track). It also demonstrates how to use nested named capture groups
(via named lists which contain named regex strings).

<<trackDbMatchAll>>=

name.pattern <- list(
  cellType=".*?",
  "_",
  sampleName=list(
    "McGill",
    sampleID=int.pattern),
  dataType="Coverage|Peaks",
  "|",
  "[^\n]+")
match.df <- namedCapture::str_match_all_variable(
  trackDb.vec,
  "track ",
  name=name.pattern,
  "(?:\n[^\n]+)*",
  "\\s+bigDataUrl ",
  bigDataUrl="[^\n]+")
head(match.df)

@

Exercise for the reader: modify the above regex in order to capture
three additional columns (red, green, blue) from the color field.

\subsection{Extracting new columns from a character column in a data.frame}

\label{sec:df_match_variable}

We also provide \verb|namedCapture::df_match_variable| which extracts text
from several columns of a data.frame, using a different named capture
regular expression for each column.

\begin{itemize}
\item It requires a data.frame as the first argument.
\item It takes a variable number of other arguments. (all of which must be
  named) For each other argument we call \verb|str_match_variable| on one
  column of the input data.frame.
\item Each argument name specifies a column of the data.frame which will
  be used as the subject in \verb|str_match_variable|.
\item Each argument value specifies a pattern to be used with
  \verb|str_match_variable|. (in list/character/function format as
  explained in the previous section)
\item The return value is a data.frame with the same number of rows as the
  input, but with an additional column for each named capture
  group. New columns are named using the convention
  \verb|oldColumnName.groupName|.
\end{itemize}
This function can greatly simplify the code required to create numeric
data columns from character data columns. For example consider the
following data which was output from the SLURM sacct command line program.

<<sacctdf>>=

(sacct.df <- data.frame(
  Elapsed=c(
    "07:04:42", "07:04:42", "07:04:49",
    "00:00:00", "00:00:00"),
  JobID=c(
    "13937810_25",
    "13937810_25.batch",
    "13937810_25.extern",
    "14022192_[1-3]",
    "14022204_[4]"),
  stringsAsFactors=FALSE))

@

Say we want to filter by the total Elapsed time (which is reported as
hours:minutes:seconds), and base job id (which is the number before
the underscore in the JobID column). We could start by converting
those character columns to integers via:

<<rangePat>>=

range.pattern <- list(
  "[[]",
  task1=int.pattern,
  list(
    "-",
    taskN=int.pattern
  ), "?",
  "[]]")
task.pattern <- list(
  task=int.pattern,
  "|",#either one task(above) or range(below)
  range.pattern)
(task.df <- namedCapture::df_match_variable(
  sacct.df,
  JobID=list(
    job=int.pattern,
    "_",
    task.pattern,
    list(
      "[.]",
      type=".*"
    ), "?"),
  Elapsed=list(
    hours=int.pattern,
    ":",
    minutes=int.pattern,
    ":",
    seconds=int.pattern)))

@

The result is another data frame with an additional column for each
named capture group. 

\section{Comparisons}
\label{sec:comparisons}
\subsection{Comparison with rex}
\label{sec:rex}
In this section we compare namedCapture verbose variable argument
syntax with the similar rex package. We have translated the rex log
parsing example to namedCapture syntax. There are two major
differences in syntax:
\begin{itemize}
\item namedCapture assumes the user knows regular expressions and can
  write them in R code; rex assumes the user knows its functions,
  which generate regex strings. E.g. the capture group "time",
  \verb|none_of("]") %>% zero_or_more()| in rex gets translated to the
  regex string \verb|[^]]*|. Thus rex code is a bit more verbose than
  namedCapture.
\item Type conversion functions. In namedCapture they are specified on the
  same line as the capture group name/pattern, whereas in rex they are
  specified after the pattern, using mutate. 
\end{itemize}

<<logsubject>>=

log.subject <- '198.214.42.14 - - [21/Jul/1995:14:31:46 -0400] "GET /images/ HTTP/1.0" 200 17688
lahal.ksc.nasa.gov - - [24/Jul/1995:12:42:40 -0400] "GET /images/USA-logosmall.gif HTTP/1.0" 200 234
199.171.112.23 - - [02/Jul/1995:02:30:34 -0400] "GET /images/KSC-logosmall.gif HTTP/1.0" 200 1204
gate3.fmr.com - - [05/Jul/1995:13:51:39 -0400] "GET /shuttle/countdown/ HTTP/1.0" 200 3985
curly02.slip.yorku.ca - - [10/Jul/1995:23:11:49 -0400] "GET /shuttle/missions/sts-70/sts-70-patch-small.gif HTTP/1.0" 200 5026
boson.epita.fr - - [15/Jul/1995:11:27:49 -0400] "GET /shuttle/missions/sts-71/movies/sts-71-mir-dock.mpg HTTP/1.0" 200 946425
134.153.50.9 - - [13/Jul/1995:11:02:50 -0400] "GET /icons/text.xbm HTTP/1.0" 200 527
port00.ventura.rain.org - - [23/Jul/1995:09:11:06 -0400] "GET /shuttle/countdown/ HTTP/1.0" 200 4324
128.159.145.91 - - [14/Jul/1995:10:38:04 -0400] "GET /statistics/images/getstats_big.gif HTTP/1.0" 200 6777
slo.eei.upmc.edu - - [25/Jul/1995:09:33:01 -0400] "GET /images/KSC-logosmall.gif HTTP/1.0" 200 1204
206.13.med.umich.edu - - [14/Jul/1995:09:11:28 -0400] "GET /shuttle/resources/orbiters/challenger-logo.gif HTTP/1.0" 200 4179'
log.subject.vec <- strsplit(log.subject, split="\n")[[1]]
result.list <- list()
result.list$namedCapture <- namedCapture::str_match_variable(
  log.subject.vec,
  "\\[",
  time="[^]]*", function(x)as.POSIXct(x, format="%d/%b/%Y:%H:%M:%S %z"),
  "\\]",
  ' "GET ',
  list(
    "[^[:space:]]+[.]", 
    filetype='[^[:space:].?"]+', tolower
  ), "?")
library(rex)
library(dplyr)
result.list$rex <- re_matches(
  log.subject.vec,
  rex(
    "[",
    capture(name = "time",
      none_of("]") %>% zero_or_more()),
      "]",
      space, double_quote, "GET", space,
      maybe(
	non_spaces, ".",
	capture(name = 'filetype',
		none_of(space, ".", "?", double_quote) %>% one_or_more())
      )
    )
  ) %>%
    mutate(filetype = tolower(filetype),
	   time = as.POSIXct(time, format="%d/%b/%Y:%H:%M:%S %z"))
with(result.list, identical(rex, namedCapture))

@

\subsection{Comparison with tidyr}
\label{sec:tidyr}

Below I show comparisons between \verb|tidyr::extract| and
\verb|namedCapture::df_match_variable| which was introduced in
Section~\ref{sec:df_match_variable}. In this
comparison we define the patterns using a list of character vectors,
with each group name on the same line as its sub-pattern.

<<tidyr>>=

range.vec <- c(
  "\\[",
  task1="[0-9]+", 
  "(?:-",#begin optional end of range.
  taskN="[0-9]+", 
  ")?", #end is optional.
  "\\]")
task.vec <- c(
  "(?:",#begin alternate
  task="[0-9]+", 
  "|",#either one task(above) or range(below)
  range.vec,
  ")")#end alternate
regex.list <- list(
  JobID=c(
    job="[0-9]+", 
    "_",
    task.vec,
    "(?:[.]",
    type=".*",
    ")?"),
  Elapsed=c(
    hours="[0-9]+",
    ":",
    minutes="[0-9]+",
    ":",
    seconds="[0-9]+"))
tidyr.df <- sacct.df
for(col.name in names(regex.list)){
  regex.vec <- regex.list[[col.name]]
  is.group <- names(regex.vec)!=""
  format.vec <- ifelse(is.group, "(%s)", "%s")
  group.vec <- sprintf(format.vec, regex.vec)
  regex <- paste(group.vec, collapse="")
  group.names <- names(regex.vec)[is.group]
  tidyr.df <- tidyr::extract(
    tidyr.df, col.name, group.names, regex, convert=TRUE)
}
tidyr.df

@

Here are some observations from the
comparison:
\begin{itemize}
\item The namedCapture code is shorter. The tidyr code is longer
  mostly because the for loop that you see below for tidyr is hidden
  inside the definition of \verb|df_match_variable|.
\item Converting extracted character groups to numeric column types is
  specified via the convert argument of tidyr::extract, which uses
  utils::type.convert. In contrast =namedCapture= supports arbitrary
  group-specific type conversion functions, which are specified= on the
  same line as the corresponding name/pattern.
\end{itemize}

\subsection{Timings}
\label{sec:timings}

TODO re2r timing figure.

\section{Discussion and conclusions}

\bibliography{RJreferences}

\address{Author One\\
  Affiliation\\
  Address\\
  Country\\
  (ORCiD if desired)\\
  \email{author1@work}}

\address{Author Two\\
  Affiliation\\
  Address\\
  Country\\
  (ORCiD if desired)\\
  \email{author2@work}}

\address{Author Three\\
  Affiliation\\
  Address\\
  Country\\
  (ORCiD if desired)\\
  \email{author3@work}}

\end{article}

\end{document}
